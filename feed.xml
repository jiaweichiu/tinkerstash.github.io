<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2018-02-14T03:00:24-08:00</updated><id>/</id><title type="html">My hideout</title><subtitle>My website. Random posts.</subtitle><author><name>Jiawei Chiu</name></author><entry><title type="html">Hello world</title><link href="/miscel/hello-world/" rel="alternate" type="text/html" title="Hello world" /><published>2018-02-10T00:00:00-08:00</published><updated>2018-02-10T00:00:00-08:00</updated><id>/miscel/hello-world</id><content type="html" xml:base="/miscel/hello-world/">&lt;h3 id=&quot;some-testing&quot;&gt;Some testing&lt;/h3&gt;

&lt;p&gt;Hello world!&lt;/p&gt;

&lt;p&gt;Testing mathjax:
&lt;script type=&quot;math/tex&quot;&gt;e^{2\pi i kx}&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-this-is-built&quot;&gt;How this is built&lt;/h3&gt;

&lt;p&gt;We fork the Minimal Mistakes repo and use it to generate static content into a Github Pages repo. We do &lt;strong&gt;not&lt;/strong&gt; need Github Pages support for Jekyll.&lt;/p&gt;

&lt;p&gt;Remember to add the following to &lt;code class=&quot;highlighter-rouge&quot;&gt;_includes/head/custom.html&lt;/code&gt; for the LaTeX to work:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text/javascript&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/script&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;&amp;gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jiawei Chiu</name></author><summary type="html">First post. Testing. Basic setup.</summary></entry><entry><title type="html">Feature engineering tricks</title><link href="/machine-learning/feature-engineering-tricks/" rel="alternate" type="text/html" title="Feature engineering tricks" /><published>2018-02-01T00:00:00-08:00</published><updated>2018-02-01T00:00:00-08:00</updated><id>/machine-learning/feature-engineering-tricks</id><content type="html" xml:base="/machine-learning/feature-engineering-tricks/">&lt;h3 id=&quot;standardization&quot;&gt;Standardization&lt;/h3&gt;

&lt;p&gt;Some algorithms are quite sensitive to the scale of each column or feature, e.g., SVM, neural nets. Here are some commons of preprocessing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Standard scaler: &lt;script type=&quot;math/tex&quot;&gt;y = \frac{x - \mu_x}{\sigma_x}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;\mu_x&lt;/script&gt; is the mean and &lt;script type=&quot;math/tex&quot;&gt;\sigma_x&lt;/script&gt; is the standard deviation. See &lt;code class=&quot;highlighter-rouge&quot;&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;. If your data is not Gaussian-like, this might turn out badly. See below for ways to convert to Gaussian. The output has zero mean and unit variance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MinMax scaler: &lt;script type=&quot;math/tex&quot;&gt;y = \frac{x - x_{\min}}{x_{\max} - x_{\min}}&lt;/script&gt;. See &lt;code class=&quot;highlighter-rouge&quot;&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;. The output is between 0 and 1.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Be careful not to standardize using the test set. Otherwise, you are cheating. It is to be derived from train set and applied to test set.&lt;/p&gt;

&lt;h3 id=&quot;binning-numerical-variables&quot;&gt;Binning numerical variables&lt;/h3&gt;

&lt;p&gt;If you have a numerical variable, you might consider binning it to enable your algorithm to ignore perturbation within a bin. This may make it easier for the algorithm to learn and generalize.&lt;/p&gt;

&lt;h3 id=&quot;grouping-categories&quot;&gt;Grouping categories&lt;/h3&gt;

&lt;p&gt;We can try to merge similar categories into one category such that there is more data per category value. This can improve the signal-to-noise ratio and makes life easier for the learning algorithm.&lt;/p&gt;

&lt;h3 id=&quot;transform-to-gaussian&quot;&gt;Transform to Gaussian&lt;/h3&gt;

&lt;p&gt;A bunch of standard statistical tools assume a Gaussian distribution, e.g., standard hypothesis testing. However, your feature might not follow this distribution. Finding a transformation to make your data follow a Gaussian distribution might require some trial and error. Look up Box-Cox transformations. The one-parameter Box-Cox transformations is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
y = \begin{cases}
\frac{x^{\lambda} - 1}{\lambda} &amp; \text{if } \lambda \neq 0 \\
\log x &amp; \text{if } \lambda = 0.
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;It is typical to try &lt;script type=&quot;math/tex&quot;&gt;\lambda=\pm \frac{1}{2}, \pm 1, \pm 2, \pm 3&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;missing-data&quot;&gt;Missing data&lt;/h3&gt;

&lt;p&gt;When data is missing, you can:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Filter these rows away;&lt;/li&gt;
  &lt;li&gt;Imputing their values, say with the mean or median;&lt;/li&gt;
  &lt;li&gt;Use algorithms that deal with missing values naturally, e.g., R &lt;code class=&quot;highlighter-rouge&quot;&gt;gbm&lt;/code&gt; package (gradient boosting).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;one-hot-encoding&quot;&gt;One-hot encoding&lt;/h3&gt;

&lt;p&gt;Categorical features may take several different values. Say they can take &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; different values. We want to create &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; columns such that for each row, only one of the &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; column values is one while the others are zeros. Essentially, we are asking the learning algorithm to learn whether “feature=&lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;” for various values &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; has any significance. Otherwise, the algorithm will be trying to perform numerical operations on your original categorical value, which may not make any sense.&lt;/p&gt;

&lt;p&gt;This is easy to do in Scikit or Tensorflow. Here is an excerpt from Scikit. There are 4 rows, 3 categorical features.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OneHotEncoder&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;categorical_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'all'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;lt;...&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'numpy.float64'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;handle_unknown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'auto'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_values_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_indices_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first categorical feature leads to two columns because it can take only two values &lt;script type=&quot;math/tex&quot;&gt;0,1&lt;/script&gt;. The second feature leads to three column because it can take three values &lt;script type=&quot;math/tex&quot;&gt;0,1,2&lt;/script&gt;. The third feature leads to four columns because it can take four values &lt;script type=&quot;math/tex&quot;&gt;0,1,2,3&lt;/script&gt;. Altogether there are &lt;script type=&quot;math/tex&quot;&gt;2+3+4=9&lt;/script&gt; columns. When asked to transform &lt;script type=&quot;math/tex&quot;&gt;0, 1, 1&lt;/script&gt;, the output is &lt;script type=&quot;math/tex&quot;&gt;(1,  0),  (0,  1,  0),  (0,  1,  0,  0)&lt;/script&gt;. Transforming &lt;script type=&quot;math/tex&quot;&gt;1,2,3&lt;/script&gt; would lead to &lt;script type=&quot;math/tex&quot;&gt;(0,  1),  (0,  0,  1),  (0,  0,  0,  1)&lt;/script&gt; instead.&lt;/p&gt;

&lt;h3 id=&quot;crossing-interacting-features&quot;&gt;Crossing interacting features&lt;/h3&gt;

&lt;p&gt;We can take arithmetic or geometric or harmonic means of two or more variables. We can cross multiple categorical features. The idea is that these features interact with each other such that simple algorithm such as linear regression or logistic regression may not pick them up together.&lt;/p&gt;

&lt;p&gt;For example, say there are two categories &lt;script type=&quot;math/tex&quot;&gt;X,Y&lt;/script&gt; and two values for each categories &lt;script type=&quot;math/tex&quot;&gt;0,1&lt;/script&gt;. Say our output increases with &lt;script type=&quot;math/tex&quot;&gt;X=1,Y=0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;X=0,Y=1&lt;/script&gt; but decreases with &lt;script type=&quot;math/tex&quot;&gt;X=0,Y=0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;X=1,Y=1&lt;/script&gt;. If we fix &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt;, it would appear &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; has no effect on our output. If we fix &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;, it would appear &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; has no effect either. The algorithm has to consider &lt;script type=&quot;math/tex&quot;&gt;X,Y&lt;/script&gt; together in order to predict well. Certain algorithms can do that, but they tend to have higher variance and require more data. It might be better to provide a hint to the algorithm by crossing features that you think are important and interacting.&lt;/p&gt;

&lt;h3 id=&quot;dimensionality-reduction&quot;&gt;Dimensionality reduction&lt;/h3&gt;

&lt;p&gt;There is a slew of dimensionality reduction techniques such as PCA, autoencoders, clustering. If we have a ton of features, it seems appropriate to do dimensionality reduction to try to quickly see how good these features are, before performing more careful feature selection.&lt;/p&gt;</content><author><name>Jiawei Chiu</name></author><summary type="html">Some common tricks for feature engineering.</summary></entry></feed>